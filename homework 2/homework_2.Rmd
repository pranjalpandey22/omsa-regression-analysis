---
output:
  pdf_document: default
  html_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Peer Grader Guidance
Please review the student expectations for peer review grading and peer review comments.  Overall, we ask that you score with accuracy. When grading your peers, you will not only learn how to improve your future homework submissions but you will also gain deeper understanding of the concepts in the assignments. When assigning scores, consider the responses to the questions given your understanding of the problem and using the solutions as a guide. Moreover, please give partial credit for a concerted effort, but also be thorough. **Add comments to your review, particularly when deducting points, to explain why the student missed the points.** Ensure your comments are specific to questions and the student responses in the assignment.


# Background

You have been contracted as a healthcare consulting company to understand the factors on which the pricing of health insurance depends. 

## Data Description

The data consists of a data frame with 1338 observations on the following 7 variables:

1. price: Response variable ($)
2. age: Quantitative variable
3. sex: Qualitative variable
4. bmi: Quantitative variable
5. children: Quantitative variable
6. smoker: Qualitative variable
7. region: Qualitative variable


## Instructions on reading the data

To read the data in `R`, save the file in your working directory (make sure you have changed the directory if different from the R working directory) and read the data using the `R` function `read.csv()`

```{r}
insurance = read.csv("C:\\Users\\pande\\OneDrive\\Desktop\\github\\omsa-regression-analysis\\homework 2\\insurance.csv", head = TRUE)

head(insurance)
```


# Question 1: Exploratory Data Analysis [15 points]

a. **4 pts** Create scatterplots of the response, *price*, against three quantitative predictors *age*, *bmi*, and *children*. Describe the general trend (direction and form) of each plot. It should be 3 separate scatter plots.
```{r}
# Price x Age
plot(insurance$price ~ insurance$age)
```

There seems to be a positive linear relationshp of high strength between price and age, as naturally was expected. There is a general increasing trend in insurance price as the age increases. However,they seem to be able to be clustered to three straight lines, with each line the variance of insurance price appears to be constant.

```{r}
# Price x BMI
plot(insurance$price ~ insurance$bmi)
```

We see clusters being formed with a strong relationship being indicated between high bmi and having an insurance policy (although the lowest bracket of policies).
Perhaps classifying this as a "soundhorn" relationship would be more appropriate as we defienitely see an increasing variance in policy price as the bmi increases.

```{r}
# Price x Children
plot(insurance$price ~ insurance$children)
```

First and foremost, this is obvously a categorical variable and that is whjy we see lines for each value of number of children. the data tells us that the price 
mostly remains independent of the number of children, and sees sort of a decrease after 4 children, although I suspect that is due to a lack of data points as having
5 children is not that common (at least now anyway!). 

b. **4 pts** What is the value of the correlation coefficient for each of the above pair of response and predictor variables? What does it tell you about your comments in part (a)?
```{r}
print(cor(insurance$price, insurance$age))
print(cor(insurance$price, insurance$bmi))
print(cor(insurance$price, insurance$children))
```

All the correlation coefficients are positive, and corr(price, age) > corr(price, bmi) > corr(price,children) ≈0, which represents relatively high, moderate, and weak positive linear 
relationships, respectively,which is in general agreement with my comments in part(a), and weak positive correlation is challenging toobserve that I concluded with almost independence 
between insurance price and children in (a).

c. **4 pts** Create box plots of the response, *price*, and the three qualitative predictors *sex*, *smoker*, and *region*. Based on these box plots, does there appear to be a relationship 
between these qualitative predictors and the response?

*Hint*: Use the given code to convert the qualitative predictors to factors.

```{r}
#make categorical variables into factors
insurance$sex<-as.factor(insurance$sex) #makes female the baseline level
insurance$smoker<-as.factor(insurance$smoker) #makes no the baseline level
insurance$region<-as.factor(insurance$region) #makes northeast the baseline level
```

```{r}
boxplot(insurance$price ~ insurance$sex)
```

The only thing to infer from this is that on average, males tend to take a higher priced insurance policy.

```{r}
boxplot(insurance$price ~ insurance$smoker)
```

VERY noticeable difference! (as it should be too!) 
Smokers will have to take a higher priced insurance, and we see that the mean insurance price is much higher for smokers as compared to non-smokers.

```{r}
boxplot(insurance$price ~ insurance$region)
```

Not much to infer from this graph, insurance price doesn't seem to be strongly related to region, although we do see a little bit of variation in terms of mean price. 
```{r}
boxplot(insurance$price ~ insurance$sex)
```


d. **3 pts** Based on the analysis above, does it make sense to run a multiple linear regression with all of the predictors?

Yes, because all the predictors have somewhat correlation with the response variable insuranceprice, as even it is hard to compare the mean insurance prices for different 
sexes or regions, the variancesfor insurance price differ; running a multiple linear regression with all the predictors can interpret thesecorrelations better by capturing 
the association of a predicting variable to the response variable conditionally,i.e., conditional of all other predicting variables in the model

# Question 2: Fitting the Multiple Linear Regression Model [12 points]

Build a multiple linear regression model, named *model1*, using the response, *price*, and all 6 predictors, and then answer the questions that follow:

a. **6 pts** Report the coefficient of determination (R-squared) for the model and give a concise interpretation of this value.
```{r}
model1 =lm(price ~ age+sex+bmi+children+smoker+region, insurance)
summary(model1)$r.squared
```

R-squared for the model is 0.7509, which means 0.7509 of total variability in the insurance pricecan be explained by the linear regression model.

b. **6 pts** Is the model of any use in predicting price? Using $\alpha = 0.05$, provide the following elements of the test of overall regression of the model: null hypothesis $H_0$, alternative hypothesis $H_a$, $F$-statistic or $p$-value, and conclusion.

```{r}
summary(model1)
```

We see that the p-value is extremely close to being ZERO. This means that at least 1 of the predictor coefficients is different from zero (the alternative). 
Thus we reject the null hypothesis and accept the alternative, so the model is apt for predicting price. 

# Question 3: Model Comparison [14 points]

a. **5 pts** Assuming a marginal relationship between *region* and *price*, perform an ANOVA $F$-test on the mean insurance prices among the different regions. Using an $\alpha$-level of 0.05, can we reject the null hypothesis that the means of the regions are equal? Please interpret.
```{r}
summary(aov(price ~ region, insurance))
```

F-tests are used to determine whether group means are equaL but since the p-value is 0.0309 < α= 0.05, we can reject this null hypothesis that the means of the regions are equal

b. **5 pts** Now, build a second multiple linear regression model, called *model2*, using *price* as the response variable, and all variables except *region* as the predictors. Conduct a partial $F$-test comparing *model2* with *model1*. What is the partial-F test p-value? Can we reject the null hypothesis that the regression coefficients for *region* variables are zero at an $\alpha$-level of 0.05?
```{r}
model2 =lm(price ~ age+sex+bmi+children+smoker, insurance)
anova(model2, model1)
```

A partial F-test is used to determine whether or not there is a statistically significant difference between a regression model and some nested version of the same model.
A nested model is simply one that contains a subset of the predictor variables in the overall regression model.

The partial-F test p-value is 0.09622 >α= 0.05, we CANNOT reject the null hypothesis that the means of the regions are equal.

c. **4 pts** What can you conclude from 3a and 3b? Do they provide the exact same results?
The regions are marginally statistically significant to the insurance price, however, NOT conditionally statistically significant on all the other predictors. 
They provide don't exactly show the same results, but completely distinct results in terms of a statistical significance level of α= 0.05

*Note: Please use model1 for all of the following questions.*

# Question 4: Coefficient Interpretation [7 points]

a. **3 pts** Interpret the estimated coefficient of *sexmale* in the context of the problem. *Make sure female is the baseline level for sex. Mention any assumptions you make about other predictors clearly when stating the interpretation.*
The estimated coefficient of sexmale means that the insurance price for a male is expected to be131.3 lower than a female holding all other predictors in the model fixed.

b. **4 pts** If the value of the *bmi* in *model1* is increased by 0.01 and the other predictors are kept constant, what change in the response would be expected?
E(∆price) = βbmi ∆bmi = 339.2×0.01 = 3.392

# Question 5: Confidence and Prediction Intervals [12 points]

a. **6 pts** Compute 90% and 95% confidence intervals (CIs) for the parameter associated with *age* for *model1*. What observations can you make about the width of these intervals?
```{r}
print(confint(model1, "age",level = 0.90))
print(confint(model1, "age",level = 0.95))
```

Under the normality assumption, the width of 90% CI is about 3.3 times the standard error, thewidth of 95% CI is about 3.92 times the standard error, which agrees with the Z-table
Just assumming the normal distribution as well it is easy to see that 95% CI covers almost about 3 Standard Deviations from the mean either side, and hence is a bigger interval than 90%. 

b. **3 pts** Using *model1*, estimate the average price for all insurance policies with the same characteristics as the first data point in the sample. What is the 95% confidence interval? Provide an interpretation of your results.
```{r}
library("dplyr")

newdata =select(head(insurance, 1), -price)
predict(model1, newdata, interval = "confidence")
```

The mean response estimation at the 95% confidence interval for the characteristics of the pointis completely different from (much higher than) the insurance price of the point 16884.92, 
so the point couldbe an outlier that makes it unrepresentative for the model as the model has a relatively high R-squared of0.7509.

c. **3 pts** Suppose that the *age* value for the first data point is increased to 50, while all other values are kept fixed. Using *model1*, predict the price of an insurance policy with these characteristics. What is the 95% prediction interval? Provide an interpretation of your results.
```{r}
newdata["age"]=50
predict(model1, newdata, interval = "prediction")
```

A prediction interval captures the uncertainty around a single value. A confidence interval captures the uncertainty around the mean predicted values. Thus, a prediction interval will always be wider than a confidence interval for the same value.

The insurance with these characteristics has predicted to have a mean that grown from 25293.71to 33256.26 with age increased from 19 to 50 while keep other characteristics unchanged, the ratio of their differences is the coefficient for age given by the model expected. 
The prediction confidence interval is ~ 10 times that of mean response estimation in (b), the age in this question is only ~ 2.6 times that of (b), so the rest of the contribution to the large confidence interval difference is in the fact that a predicted confidence interval for
the response is substantially larger than a estimated confidence interval for the response at a same level.

